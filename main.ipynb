{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJET MACH_BDA_DATAVIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"d0r1h/customer_churn\")\n",
    "\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "df_reset = df.copy() # copie pour ne pas recharger tout le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_dataframe():\n",
    "    return df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df):\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop(columns=['security_no', 'referral_id'],inplace=True)\n",
    "    \n",
    "    df['medium_of_operation'] = df['medium_of_operation'].replace('?', 'Unknown')\n",
    "    \n",
    "    df = df[df['days_since_last_login'] > 0]\n",
    "    df = df[df['avg_time_spent'] > 0]\n",
    "    df = df[df['points_in_wallet'] > 0]\n",
    "    df = df[df['avg_frequency_login_days'] != \"Error\"]\n",
    "    \n",
    "    df['avg_frequency_login_days'] = pd.to_numeric(df['avg_frequency_login_days'])\n",
    "    \n",
    "    df['joining_date'] = pd.to_datetime(df['joining_date'], format='%d-%m-%Y')\n",
    "    df['last_visit_time'] = pd.to_datetime(df['last_visit_time'], format='%H:%M:%S').dt.time\n",
    "\n",
    "    df['joining_year'] = df['joining_date'].dt.year\n",
    "    df['joining_month'] = df['joining_date'].dt.month\n",
    "    df['joining_day'] = df['joining_date'].dt.day\n",
    "\n",
    "    df['last_visit_hour'] = df['last_visit_time'].apply(lambda x: x.hour)\n",
    "    df['last_visit_minute'] = df['last_visit_time'].apply(lambda x: x.minute)\n",
    "\n",
    "    df.drop(columns=['joining_date', 'last_visit_time'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardisation des données numériques (mettre toutes les valeurs entre 0 et 1, pas sûr s'il y a vraiment besoin):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_numeric_columns(df):\n",
    "    numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    df[numeric_columns] = MinMaxScaler().fit_transform(df[numeric_columns])\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encodage des données non numériques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_columns(df):\n",
    "    non_numeric_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    dict_encode = { value: index for index, value in enumerate(non_numeric_columns) }\n",
    "    \n",
    "    encoded_df = df.copy()\n",
    "    \n",
    "    for col in dict_encode:\n",
    "        l_occurences = df[col].unique()\n",
    "        dict_encode[col] = { value: index for index, value in enumerate(l_occurences) }\n",
    "        encoded_df[col] = encoded_df[col].apply(lambda x : dict_encode[col][x])\n",
    "    \n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = reset_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_dataframe(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je n'ai pas encore reussi a encoder les colonnes non numeriques"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse et visualisation exploratoire des Données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrice de corrélation pour voir si certaines features sont redondantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = encode_columns(df).corr()\n",
    "plt.figure(figsize=(25, 25))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Matrice de corrélation')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation de plusieurs modèles avec les bonnes métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = encode_columns(df)\n",
    "df = normalize_numeric_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['churn_risk_score'])\n",
    "y = df['churn_risk_score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'SVM': SVC(kernel='linear'),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    results[model_name] = accuracy\n",
    "\n",
    "for model_name, accuracy in results.items():\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation des meilleurs modèles (GDBoosting et RandomForest) pour améliorer leur accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "random_search_gdb = RandomizedSearchCV(estimator=model, param_distributions=param_dist, \n",
    "                                   n_iter=100, cv=5, n_jobs=-1, verbose=2, random_state=42, scoring='accuracy')\n",
    "\n",
    "random_search_gdb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters found: \", random_search_gdb.best_params_)\n",
    "\n",
    "print(\"Best cross-validation score: {:.2f}\".format(random_search_gdb.best_score_))\n",
    "\n",
    "best_model_gdb = random_search_gdb.best_estimator_\n",
    "y_pred_gdb = best_model_gdb.predict(X_test)\n",
    "accuracy_gdb = accuracy_score(y_test, y_pred_gdb)\n",
    "\n",
    "print(\"Test set accuracy: {:.2f}\".format(accuracy_gdb))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters found: {'subsample': 1.0, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 5, 'learning_rate': 0.1}\n",
    "Best cross-validation score: 0.94\n",
    "Test set accuracy: 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': np.arange(100, 501, 50),\n",
    "    'max_depth': np.arange(3, 21, 2),\n",
    "    'min_samples_split': np.arange(2, 21, 2),\n",
    "    'min_samples_leaf': np.arange(1, 11, 1),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "random_search_rf = RandomizedSearchCV(estimator=model, param_distributions=param_distributions, n_iter=100, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "random_search_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters found: \", random_search_rf.best_params_)\n",
    "\n",
    "print(\"Best cross-validation score: {:.2f}\".format(random_search_rf.best_score_))\n",
    "\n",
    "best_model_rf = random_search_rf.best_estimator_\n",
    "y_pred_rf = best_model_rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Test set accuracy: {:.2f}\".format(accuracy_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters found:  {'n_estimators': 250, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_depth': 19, 'bootstrap': False}\n",
    "Best cross-validation score: 0.94\n",
    "Test set accuracy: 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_importance(model,coeff_method=None):\n",
    "    if coeff_method == 'arbres':\n",
    "        feature_importances = model.feature_importances_\n",
    "    else:\n",
    "        feature_importances = model.coef_[0]\n",
    "    \n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': feature_importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    return feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = features_importance(models['Random Forest'], 'arbres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiser et interpreter les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
    "plt.title('Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
